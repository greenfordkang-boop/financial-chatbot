import streamlit as st
import tempfile
import os
from datetime import datetime
from pathlib import Path
import json

from pdf_processor import process_pdf, get_financial_context
from data_store import (
    save_extracted_data,
    load_extracted_data,
    list_saved_files,
    get_all_data_context,
    delete_extracted_data,
    save_chat_history,
    load_chat_history,
    list_chat_sessions,
    delete_chat_history
)
from claude_client import ClaudeClient


# ì˜êµ¬ ì €ì¥ì†Œ ì„¤ì •
PERSISTENT_DATA_DIR = Path("persistent_data")
PERSISTENT_DATA_DIR.mkdir(exist_ok=True)

COMPANIES_FILE = PERSISTENT_DATA_DIR / "companies.json"
PDF_STORAGE_DIR = PERSISTENT_DATA_DIR / "pdf_files"
PDF_STORAGE_DIR.mkdir(exist_ok=True)

# í† í° ì œí•œ ì„¤ì •
MAX_CONTEXT_TOKENS = 150000
CHARS_PER_TOKEN = 4


def estimate_tokens(text):
    """í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì •"""
    return len(text) // CHARS_PER_TOKEN


def truncate_context(context, max_tokens=MAX_CONTEXT_TOKENS):
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ í† í° ì œí•œ ë‚´ë¡œ ì¶•ì•½"""
    estimated_tokens = estimate_tokens(context)
    
    if estimated_tokens <= max_tokens:
        return context, False
    
    ratio = max_tokens / estimated_tokens
    max_chars = int(len(context) * ratio * 0.95)
    
    truncated = context[:max_chars]
    truncated += "\n\n... [ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë©ë‹ˆë‹¤. íŠ¹ì • íšŒì‚¬ë‚˜ ì—°ë„ë¥¼ ì§€ì •í•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.]"
    
    return truncated, True


def smart_context_selection(selected_companies, question):
    """ì§ˆë¬¸ì— ê°€ì¥ ê´€ë ¨ìˆëŠ” ë°ì´í„°ë§Œ ì„ íƒ"""
    if not selected_companies:
        return get_all_data_context()
    
    saved_files = list_saved_files()
    selected_data = []
    
    import re
    years = re.findall(r'20\d{2}', question)
    
    for filename in saved_files:
        for company in selected_companies:
            if filename.startswith(f"{company}_"):
                if years:
                    if any(year in filename for year in years):
                        data = load_extracted_data(filename)
                        if data:
                            selected_data.append(data)
                else:
                    data = load_extracted_data(filename)
                    if data:
                        selected_data.append(data)
    
    if not selected_data:
        return "ì„ íƒëœ íšŒì‚¬ì˜ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    context_parts = []
    for data in selected_data:
        company_name = data.get('company_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        filename = data.get('original_filename', '')
        
        context_parts.append(f"\n\n=== {company_name} - {filename} ===\n")
        context_parts.append(data.get('text', ''))
    
    full_context = "\n".join(context_parts)
    truncated_context, was_truncated = truncate_context(full_context)
    
    if was_truncated:
        warning = f"\n\nâš ï¸ ì°¸ê³ : ë°ì´í„°ê°€ ë§ì•„ ì¼ë¶€ë§Œ ë¶„ì„ì— ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ({len(selected_data)}ê°œ íŒŒì¼)"
        truncated_context = warning + truncated_context
    
    return truncated_context


def auto_migrate_legacy_data():
    """ê¸°ì¡´ ë°ì´í„° ìë™ ê°ì§€ ë° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    extracted_dir = Path("extracted_data")
    if not extracted_dir.exists():
        return 0
    
    all_files = list(extracted_dir.glob("*.json"))
    legacy_files = []
    
    for file in all_files:
        filename = file.stem
        if '_' not in filename or not filename.split('_')[0] in get_all_company_names():
            legacy_files.append(file)
    
    if not legacy_files:
        return 0
    
    legacy_company = "ê¸°ì¡´ë°ì´í„°"
    companies = load_companies()
    
    if legacy_company not in companies:
        companies[legacy_company] = {
            "created_at": datetime.now().isoformat(),
            "file_count": 0,
            "auto_migrated": True
        }
        save_companies(companies)
    
    migrated = 0
    for old_file in legacy_files:
        try:
            with open(old_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if 'company_name' in data:
                continue
            
            original_name = old_file.name
            data['company_name'] = legacy_company
            data['original_filename'] = original_name.replace('.json', '')
            data['migrated_from_legacy'] = True
            
            new_filename = f"{legacy_company}_{original_name}"
            new_path = extracted_dir / new_filename
            
            with open(new_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            migrated += 1
            
            backup_dir = Path("backup_legacy_data")
            backup_dir.mkdir(exist_ok=True)
            old_file.rename(backup_dir / old_file.name)
            
        except Exception as e:
            pass
    
    if migrated > 0:
        update_company_file_count(legacy_company)
    
    return migrated


def get_all_company_names():
    """ëª¨ë“  íšŒì‚¬ëª… ë°˜í™˜"""
    companies = load_companies()
    return list(companies.keys())


def load_companies():
    """ì €ì¥ëœ íšŒì‚¬ ëª©ë¡ ë¡œë“œ"""
    if COMPANIES_FILE.exists():
        try:
            with open(COMPANIES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}


def save_companies(companies):
    """íšŒì‚¬ ëª©ë¡ ì €ì¥"""
    with open(COMPANIES_FILE, 'w', encoding='utf-8') as f:
        json.dump(companies, f, ensure_ascii=False, indent=2)


def save_pdf_permanently(uploaded_file, company_name):
    """PDFë¥¼ ì˜êµ¬ ì €ì¥ì†Œì— ì €ì¥"""
    company_dir = PDF_STORAGE_DIR / company_name
    company_dir.mkdir(exist_ok=True)
    
    file_path = company_dir / uploaded_file.name
    with open(file_path, 'wb') as f:
        f.write(uploaded_file.getvalue())
    
    return file_path


def get_stored_pdfs(company_name):
    """ì €ì¥ëœ PDF íŒŒì¼ ëª©ë¡"""
    company_dir = PDF_STORAGE_DIR / company_name
    if not company_dir.exists():
        return []
    
    return sorted([f.name for f in company_dir.glob("*.pdf")])


def delete_pdf_file(company_name, filename):
    """PDF íŒŒì¼ ì‚­ì œ"""
    file_path = PDF_STORAGE_DIR / company_name / filename
    if file_path.exists():
        file_path.unlink()


def delete_company_folder(company_name):
    """íšŒì‚¬ í´ë” ì „ì²´ ì‚­ì œ"""
    company_dir = PDF_STORAGE_DIR / company_name
    if company_dir.exists():
        import shutil
        shutil.rmtree(company_dir)


def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - ëŒ€í™” ê¸°ë¡ ë³´ì¡´ ê°•í™”"""
    # í˜„ì¬ ì„¸ì…˜ ID ìœ ì§€ ë˜ëŠ” ìƒì„±
    if "current_session" not in st.session_state:
        # ê°€ì¥ ìµœê·¼ ì„¸ì…˜ ì°¾ê¸°
        sessions = list_chat_sessions()
        if sessions and len(sessions) > 0:
            # ìµœê·¼ ì„¸ì…˜ ìë™ ë³µêµ¬
            latest_session = sessions[0]["session_id"]
            st.session_state.current_session = latest_session
            st.session_state.session_restored = True
        else:
            st.session_state.current_session = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ë©”ì‹œì§€ ë¡œë“œ
    if "messages" not in st.session_state:
        st.session_state.messages = load_chat_history(st.session_state.current_session)
    
    if "financial_context" not in st.session_state:
        st.session_state.financial_context = ""
    
    if "client" not in st.session_state:
        try:
            st.session_state.client = ClaudeClient()
        except ValueError:
            st.session_state.client = None
    
    if "selected_companies" not in st.session_state:
        st.session_state.selected_companies = []
    
    if "companies" not in st.session_state:
        migrated_count = auto_migrate_legacy_data()
        if migrated_count > 0:
            st.session_state.migration_message = f"âœ… ê¸°ì¡´ ë°ì´í„° {migrated_count}ê°œë¥¼ 'ê¸°ì¡´ë°ì´í„°' íšŒì‚¬ë¡œ ìë™ ì´ë™í–ˆìŠµë‹ˆë‹¤."
        st.session_state.companies = load_companies()


def get_company_folders():
    """ì €ì¥ëœ íšŒì‚¬ ëª©ë¡ ë°˜í™˜"""
    companies = load_companies()
    return sorted(companies.keys())


def add_company(company_name):
    """ìƒˆ íšŒì‚¬ ì¶”ê°€"""
    companies = load_companies()
    if company_name not in companies:
        companies[company_name] = {
            "created_at": datetime.now().isoformat(),
            "file_count": 0
        }
        save_companies(companies)
        st.session_state.companies = companies
        return True
    return False


def update_company_file_count(company_name):
    """íšŒì‚¬ì˜ íŒŒì¼ ê°œìˆ˜ ì—…ë°ì´íŠ¸"""
    companies = load_companies()
    if company_name in companies:
        files = get_company_files(company_name)
        companies[company_name]["file_count"] = len(files)
        save_companies(companies)


def save_company_file(uploaded_file, company_name):
    """PDF ì €ì¥ ë° ë¶„ì„"""
    try:
        pdf_path = save_pdf_permanently(uploaded_file, company_name)
        data = process_pdf(str(pdf_path))
        
        data['company_name'] = company_name
        data['original_filename'] = uploaded_file.name
        data['stored_path'] = str(pdf_path)
        
        estimated_tokens = estimate_tokens(data.get('text', ''))
        
        if estimated_tokens > 50000:
            st.warning(f"âš ï¸ í° íŒŒì¼: ì•½ {estimated_tokens:,} í† í°. íŠ¹ì • ì—°ë„ë‚˜ í•­ëª©ì„ ì§€ì •í•´ì„œ ì§ˆë¬¸í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤.")
        
        save_extracted_data(data, f"{company_name}_{uploaded_file.name}")
        update_company_file_count(company_name)
        
        return True, None
        
    except Exception as e:
        return False, str(e)


def get_company_files(company_name):
    """íšŒì‚¬ì˜ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    saved_files = list_saved_files()
    company_files = []
    
    for filename in saved_files:
        if filename.startswith(f"{company_name}_"):
            original_name = filename[len(company_name)+1:]
            if original_name.endswith('.json'):
                original_name = original_name[:-5]
            company_files.append(original_name)
    
    return sorted(set(company_files))


def get_selected_companies_context():
    """ì„ íƒëœ íšŒì‚¬ë“¤ì˜ ì¬ë¬´ ë°ì´í„°"""
    if not st.session_state.selected_companies:
        context = get_all_data_context()
        truncated, was_truncated = truncate_context(context)
        if was_truncated:
            st.warning("âš ï¸ ë°ì´í„°ê°€ ë§ì•„ ì¼ë¶€ë§Œ í‘œì‹œë©ë‹ˆë‹¤. íŠ¹ì • íšŒì‚¬ë‚˜ ì—°ë„ë¥¼ ì„ íƒí•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤.")
        return truncated
    
    saved_files = list_saved_files()
    selected_data = []
    
    for filename in saved_files:
        for company in st.session_state.selected_companies:
            if filename.startswith(f"{company}_"):
                data = load_extracted_data(filename)
                if data:
                    selected_data.append(data)
    
    if not selected_data:
        return "ì„ íƒëœ íšŒì‚¬ì˜ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    context_parts = []
    total_tokens = 0
    
    for data in selected_data:
        company_name = data.get('company_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        filename = data.get('original_filename', '')
        text = data.get('text', '')
        
        tokens = estimate_tokens(text)
        total_tokens += tokens
        
        context_parts.append(f"\n\n=== {company_name} - {filename} ===\n")
        context_parts.append(text)
    
    full_context = "\n".join(context_parts)
    truncated, was_truncated = truncate_context(full_context)
    
    if was_truncated:
        st.warning(f"âš ï¸ ë°ì´í„°ê°€ ë§ì•„ ì¼ë¶€ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤. ({len(selected_data)}ê°œ íŒŒì¼, ì•½ {total_tokens:,} í† í°)")
    
    return truncated


def display_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])


def load_session(session_id: str):
    """ì´ì „ ì„¸ì…˜ ë¡œë“œ"""
    # í˜„ì¬ ì„¸ì…˜ ì €ì¥
    if st.session_state.messages:
        save_chat_history(st.session_state.messages, st.session_state.current_session)
    
    # ìƒˆ ì„¸ì…˜ ë¡œë“œ
    st.session_state.current_session = session_id
    st.session_state.messages = load_chat_history(session_id)


def rename_company(old_name, new_name):
    """íšŒì‚¬ëª… ë³€ê²½"""
    try:
        companies = load_companies()
        if old_name not in companies:
            return False
        
        if new_name in companies:
            st.error(f"'{new_name}'ì€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íšŒì‚¬ëª…ì…ë‹ˆë‹¤")
            return False
        
        companies[new_name] = companies.pop(old_name)
        save_companies(companies)
        
        extracted_dir = Path("extracted_data")
        for file in extracted_dir.glob(f"{old_name}_*.json"):
            new_filename = file.name.replace(f"{old_name}_", f"{new_name}_", 1)
            new_path = extracted_dir / new_filename
            
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            data['company_name'] = new_name
            with open(new_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            file.unlink()
        
        old_dir = PDF_STORAGE_DIR / old_name
        new_dir = PDF_STORAGE_DIR / new_name
        if old_dir.exists():
            old_dir.rename(new_dir)
        
        return True
        
    except Exception as e:
        st.error(f"íšŒì‚¬ëª… ë³€ê²½ ì‹¤íŒ¨: {e}")
        return False


def main():
    st.set_page_config(
        page_title="ì¬ë¬´ì œí‘œ ë¹„êµ ë¶„ì„ ì±—ë´‡",
        page_icon="ğŸ“Š",
        layout="wide"
    )

    st.title("ğŸ“Š ì¬ë¬´ì œí‘œ ë¹„êµ ë¶„ì„ ì±—ë´‡")
    st.caption("íšŒì‚¬ë³„ ì¬ë¬´ì œí‘œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¹„êµ ë¶„ì„í•˜ì„¸ìš” | ğŸ’¾ ì˜êµ¬ ì €ì¥ | ğŸ”„ ìë™ í˜¸í™˜ | ğŸ¯ ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ | ğŸ’¬ ëŒ€í™” ê¸°ë¡ ìë™ ë³µêµ¬")

    init_session_state()

    # ì„¸ì…˜ ë³µêµ¬ ë©”ì‹œì§€
    if "session_restored" in st.session_state and st.session_state.session_restored:
        if st.session_state.messages:
            st.success(f"âœ… ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ìë™ìœ¼ë¡œ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤. ({len(st.session_state.messages)}ê°œ ë©”ì‹œì§€)")
        del st.session_state.session_restored

    # ë§ˆì´ê·¸ë ˆì´ì…˜ ë©”ì‹œì§€
    if "migration_message" in st.session_state:
        st.success(st.session_state.migration_message)
        del st.session_state.migration_message

    # ì‚¬ì´ë“œë°” (ì´í•˜ ë™ì¼ - ì½”ë“œ ìƒëµ)
    with st.sidebar:
        st.header("ğŸ¢ íšŒì‚¬ë³„ ë°ì´í„° ê´€ë¦¬")

        if st.session_state.client is None:
            st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        else:
            st.success("âœ… API ì—°ê²°ë¨")

        companies = get_company_folders()
        total_files = sum([len(get_company_files(c)) for c in companies])
        st.caption(f"ğŸ’¾ {len(companies)}ê°œ íšŒì‚¬ | {total_files}ê°œ íŒŒì¼")

        st.divider()

        # ìƒˆ íšŒì‚¬ ì¶”ê°€
        st.subheader("â• ìƒˆ íšŒì‚¬ ì¶”ê°€")
        new_company = st.text_input("íšŒì‚¬ëª… ì…ë ¥", placeholder="ì˜ˆ: ìš°ë¦¬íšŒì‚¬")
        
        if new_company and st.button("íšŒì‚¬ ì¶”ê°€", use_container_width=True):
            if add_company(new_company):
                st.success(f"âœ… '{new_company}' ì¶”ê°€ë¨")
                st.rerun()

        st.divider()

        # íŒŒì¼ ì—…ë¡œë“œ
        st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        if companies:
            selected_company = st.selectbox("íšŒì‚¬ ì„ íƒ", [""] + companies)
            
            if selected_company:
                uploaded_files = st.file_uploader(
                    f"{selected_company}ì˜ ë¬¸ì„œ",
                    type=["pdf"],
                    accept_multiple_files=True,
                    key=f"upload_{selected_company}"
                )
                
                if uploaded_files and st.button("ğŸ“¥ ì—…ë¡œë“œ ë° ë¶„ì„", use_container_width=True):
                    progress_bar = st.progress(0)
                    success_count = 0
                    
                    for idx, file in enumerate(uploaded_files):
                        status_text = st.empty()
                        status_text.text(f"ë¶„ì„ ì¤‘: {file.name}")
                        
                        success, error = save_company_file(file, selected_company)
                        if success:
                            success_count += 1
                        else:
                            st.error(f"âŒ {file.name}: {error}")
                        
                        progress_bar.progress((idx + 1) / len(uploaded_files))
                        status_text.empty()
                    
                    progress_bar.empty()
                    st.success(f"âœ… {success_count}/{len(uploaded_files)}ê°œ íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
                    st.rerun()

        st.divider()

        # ë¹„êµ ë¶„ì„ ëŒ€ìƒ
        st.subheader("ğŸ” ë¹„êµ ë¶„ì„ ëŒ€ìƒ")
        
        if companies:
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ì „ì²´ ì„ íƒ", use_container_width=True):
                    st.session_state.selected_companies = companies.copy()
                    st.rerun()
            with col2:
                if st.button("ì„ íƒ í•´ì œ", use_container_width=True):
                    st.session_state.selected_companies = []
                    st.rerun()
            
            for company in companies:
                files = get_company_files(company)
                is_selected = company in st.session_state.selected_companies
                
                if st.checkbox(
                    f"ğŸ“ {company} ({len(files)}ê°œ)",
                    value=is_selected,
                    key=f"check_{company}"
                ):
                    if company not in st.session_state.selected_companies:
                        st.session_state.selected_companies.append(company)
                else:
                    if company in st.session_state.selected_companies:
                        st.session_state.selected_companies.remove(company)

        st.divider()

        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        st.subheader("ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬")
        st.caption(f"í˜„ì¬: {st.session_state.current_session}")

        if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘", use_container_width=True):
            if st.session_state.messages:
                save_chat_history(st.session_state.messages, st.session_state.current_session)
            st.session_state.current_session = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.session_state.messages = []
            st.rerun()

        sessions = list_chat_sessions()
        if sessions:
            st.caption(f"ğŸ’¾ ì €ì¥ëœ ëŒ€í™”: {len(sessions)}ê°œ")
            for session in sessions[:15]:  # ìµœê·¼ 15ê°œ í‘œì‹œ
                session_id = session["session_id"]
                msg_count = session["message_count"]

                col1, col2 = st.columns([3, 1])
                with col1:
                    try:
                        date_str = datetime.strptime(session_id, "%Y%m%d_%H%M%S").strftime("%m/%d %H:%M")
                    except:
                        date_str = session_id[:13]

                    # í˜„ì¬ ì„¸ì…˜ í‘œì‹œ
                    label = f"ğŸ“ {date_str} ({msg_count}ê±´)"
                    if session_id == st.session_state.current_session:
                        label = f"ğŸ”´ {date_str} ({msg_count}ê±´) [í˜„ì¬]"

                    if st.button(label, key=f"load_{session_id}", use_container_width=True):
                        load_session(session_id)
                        st.rerun()

                with col2:
                    if st.button("ğŸ—‘ï¸", key=f"del_session_{session_id}"):
                        delete_chat_history(session_id)
                        st.rerun()

    # ë©”ì¸ ì˜ì—­
    if st.session_state.selected_companies:
        st.info(f"ğŸ” ë¶„ì„ ëŒ€ìƒ: {', '.join(st.session_state.selected_companies)}")
    
    if not st.session_state.financial_context:
        st.session_state.financial_context = get_selected_companies_context()

    display_chat_history()

    if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”..."):
        if st.session_state.client is None:
            st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                history = st.session_state.messages[:-1]
                smart_context = smart_context_selection(st.session_state.selected_companies, prompt)

                try:
                    response = st.session_state.client.ask(
                        question=prompt,
                        financial_context=smart_context,
                        conversation_history=history
                    )
                    st.markdown(response)
                except Exception as e:
                    if "too long" in str(e):
                        st.error("âš ï¸ ë°ì´í„°ê°€ ë§ìŠµë‹ˆë‹¤. íŠ¹ì • íšŒì‚¬ë‚˜ ì—°ë„ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
                        response = "ë°ì´í„°ê°€ ë§ì•„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŠ¹ì • íšŒì‚¬ë‚˜ ì—°ë„ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”."
                    else:
                        st.error(f"ì˜¤ë¥˜: {e}")
                        response = f"ì˜¤ë¥˜: {e}"
                    st.markdown(response)

        st.session_state.messages.append({"role": "assistant", "content": response})
        save_chat_history(st.session_state.messages, st.session_state.current_session)


if __name__ == "__main__":
    main()
